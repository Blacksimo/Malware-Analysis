
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{Machine Learning for Malware Analysis}
    
    \author{Simone Faricelli 1647406 }
    \date{November 2018}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

The purpose of this project is to develop a valuable tool to recognize
and classify different kind of Malware Application, running on
AndroidOS, through the use of several Machine Learning Classifiers.

In order to train the above-mentioned classifiers, we're taking
advantage of the
\href{https://www.sec.cs.tu-bs.de/~danarp/drebin/index.html}{Drebin
Dataset}, which provide us 5,560 malevolent files from 179 different
malware families, collected in the period of August 2010 to October
2012.

From those applications we are extracting features through the
manifest.xml file and the disassembled code.

    \hypertarget{a-classification-problem}{%
\section{A Classification Problem}\label{a-classification-problem}}

Classification belongs to the category of supervised learning where the
targets (or labels or categories) are also provided with the input data
and it is, in fact, the process of predicting the class of given data
points. Classification predictive modeling is the task of approximating
a target function (f) from input variables (X) to discrete output
variables (y).

The input variable chosen for this project is a list of vectors, each of
which specify, for each malware, the features of the application itself,
previously retrieved from a dictionary of all the features.

As expected, the output variable is a list containing the category of
each malware.

    \hypertarget{dataset}{%
\section{Dataset}\label{dataset}}

\hypertarget{selective-extraction}{%
\subsubsection{Selective Extraction}\label{selective-extraction}}

The Drebin Dataset mentioned above contains not only examples of
features of malware files, but also a huge quantity of non-malware
applications, which are not useful for our classification goal.

A selective extraction is therefore performed through a python script,
picking only the malware files, specified in the csv file, from the
130.000 samples.

\newpage

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{k+kn}{import} \PY{n+nn}{csv}
        \PY{k+kn}{from} \PY{n+nn}{zipfile} \PY{k}{import} \PY{n}{ZipFile}
        \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k}{import} \PY{n}{tqdm}
        
        \PY{n}{csvName} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sha256\PYZus{}family.csv}\PY{l+s+s1}{\PYZsq{}}
        \PY{n}{malware} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{p}{)}
        \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset/}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n}{csvName}\PY{p}{)} \PY{k}{as} \PY{n}{csvFile}\PY{p}{:}
            \PY{n}{reader} \PY{o}{=} \PY{n}{csv}\PY{o}{.}\PY{n}{reader}\PY{p}{(}\PY{n}{csvFile}\PY{p}{)}
            \PY{n+nb}{next}\PY{p}{(}\PY{n}{reader}\PY{p}{)}
            \PY{k}{for} \PY{n}{row} \PY{o+ow}{in} \PY{n}{reader}\PY{p}{:}
                \PY{n}{malware}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{row}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
        
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Extracting }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{malware}\PY{p}{)}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ files from the Drebin Dataset}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
        \PY{k}{with} \PY{n}{ZipFile}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{drebin.zip}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{myzip}\PY{p}{:}
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{malware}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                \PY{n}{myzip}\PY{o}{.}\PY{n}{extract}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{drebin/}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n}{csvName}\PY{p}{)}
                \PY{n}{myzip}\PY{o}{.}\PY{n}{extract}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{drebin/feature\PYZus{}vectors/}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n}{malware}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Extracting  5560  files from the Drebin Dataset

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
100\%|| 5560/5560 [01:58<00:00, 47.09it/s]

    \end{Verbatim}

    \hypertarget{development}{%
\section{Development}\label{development}}

\hypertarget{libraries-and-global-variables}{%
\subsubsection{Libraries and Global
Variables}\label{libraries-and-global-variables}}

In the following section the required libraries are imported and the
global variables initialized. For this project, wide use of the python
library for machine learning called ``scikit-learn'' is done. That
particular library needs to be installed first.

\newpage

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{o}{\PYZpc{}}\PY{k}{matplotlib} notebook
        \PY{k+kn}{import} \PY{n+nn}{os}\PY{o}{,} \PY{n+nn}{sys}\PY{o}{,} \PY{n+nn}{csv}\PY{o}{,} \PY{n+nn}{time}\PY{o}{,} \PY{n+nn}{json}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt} 
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{naive\PYZus{}bayes} \PY{k}{import} \PY{n}{MultinomialNB}\PY{p}{,} \PY{n}{GaussianNB}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{classification\PYZus{}report}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm} \PY{k}{import} \PY{n}{LinearSVC}\PY{p}{,} \PY{n}{SVC}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{RandomForestClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{accuracy\PYZus{}score}\PY{p}{,} \PY{n}{log\PYZus{}loss}
        \PY{k+kn}{from} \PY{n+nn}{urllib}\PY{n+nn}{.}\PY{n+nn}{parse} \PY{k}{import} \PY{n}{urlsplit}
        
        \PY{n}{datasetFolder} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{drebin/}\PY{l+s+s1}{\PYZsq{}}
        \PY{n}{featuresFolder} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}vectors/}\PY{l+s+s1}{\PYZsq{}}
        \PY{n}{csvName} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sha256\PYZus{}family.csv}\PY{l+s+s1}{\PYZsq{}}
        \PY{n}{dictionaryName} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dictionary.json}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}

    \hypertarget{defining-malware-dataset-dictionary}{%
\subsubsection{Defining Malware Dataset \&
Dictionary}\label{defining-malware-dataset-dictionary}}

The provided dataset is composed of examples of malware and non-malware
data, but in order to train the classifier the focus is moved onto the
malevolent files. In the block below, those two categories are being
separated using the cvs file as reference.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} List of all the files in debrin dataset}
        \PY{n}{dataset} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{listdir}\PY{p}{(}\PY{n}{datasetFolder} \PY{o}{+} \PY{n}{featuresFolder}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Define list for malware and non\PYZhy{}malware files}
        \PY{n}{malware} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Create malware dictionary from the csv file, with the file name and the type of each one}
        \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{n}{datasetFolder} \PY{o}{+} \PY{n}{csvName}\PY{p}{)} \PY{k}{as} \PY{n}{csvFile}\PY{p}{:}
            \PY{n}{reader} \PY{o}{=} \PY{n}{csv}\PY{o}{.}\PY{n}{reader}\PY{p}{(}\PY{n}{csvFile}\PY{p}{)}
            \PY{n+nb}{next}\PY{p}{(}\PY{n}{reader}\PY{p}{)}
            \PY{n}{malwareDictionary} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{row}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{:} \PY{n}{row}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{k}{for} \PY{n}{row} \PY{o+ow}{in} \PY{n}{reader}\PY{p}{\PYZcb{}}
        
        \PY{c+c1}{\PYZsh{} Separate the file names}
        \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n}{dataset}\PY{p}{:}
            \PY{k}{if} \PY{n}{i} \PY{o+ow}{in} \PY{n}{malwareDictionary}\PY{p}{:}
                \PY{n}{malware}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{i}\PY{p}{)}
        
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of malwares in the dataset:}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{malware}\PY{p}{)}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Number of malwares in the dataset:	 5560

    \end{Verbatim}

    \hypertarget{feature-and-malware-categories}{%
\subsubsection{Feature and Malware
Categories}\label{feature-and-malware-categories}}

For a matter of knowledge, the features contained in the dataset and
written into the files, are being collected, listed and printed. Also
empty files are removed from the feature analysis.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} Collect all the features from the files of the dataset}
        \PY{n}{categoryList} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{p}{)}
        \PY{k}{for} \PY{n}{file} \PY{o+ow}{in} \PY{n}{malware}\PY{p}{:}
            \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{n}{datasetFolder} \PY{o}{+} \PY{n}{featuresFolder} \PY{o}{+} \PY{n}{file}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
                \PY{n}{content} \PY{o}{=} \PY{n}{f}\PY{o}{.}\PY{n}{readlines}\PY{p}{(}\PY{p}{)}
                \PY{k}{for} \PY{n}{line} \PY{o+ow}{in} \PY{n}{content}\PY{p}{:}
                    \PY{k}{try}\PY{p}{:}
                        \PY{n}{category}\PY{p}{,} \PY{n}{string} \PY{o}{=} \PY{n}{line}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{::}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                        \PY{k}{if} \PY{n}{category} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{categoryList}\PY{p}{:}
                            \PY{n}{categoryList}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{category}\PY{p}{)}
                    \PY{k}{except}\PY{p}{:}
                        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Empty file: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{file}\PY{p}{)}
        
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The features can be divided in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
              \PY{n+nb}{len}\PY{p}{(}\PY{n}{categoryList}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{different sets:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{categoryList}\PY{p}{)}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Empty file:  3de513a148400b457dd8d8fa9238804db3ec031a0b526d4a04b77e5112aa2dcf
Empty file:  6c6eeed1b91913db0d6232edb1979c67d6fb48ca3da4f83dc49fb565a4e5f4fe
Empty file:  76e91e1f9cc3422c333e51b65bb98dd50d00f1f45a15d2008807b06c125e651a
Empty file:  df2c357f513c270cd1d06418e4eaf64aeb6b2d947149e83ed4f42c88286b76a7
Empty file:  f6239ba0487ffcf4d09255dba781440d2600d3c509e66018e6a5724912df34a9
The features can be divided in 10 different sets:
	 api\_call
	 feature
	 url
	 service\_receiver
	 permission
	 call
	 intent
	 real\_permission
	 activity
	 provider

    \end{Verbatim}

    As for the features, also malware categories are being collected from
the malware dictionary created above, and taken into account only if the
number of their samples is greater that 20. From this list, the output
vector for the training will be generated.

\newpage
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} Collect all the classes from the files of the dataset}
        \PY{n}{classes} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{n}{counter} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{k}{for} \PY{n}{key}\PY{p}{,} \PY{n}{value} \PY{o+ow}{in} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{malwareDictionary}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{k}{if} \PY{o+ow}{not} \PY{n}{value} \PY{o+ow}{in} \PY{n}{classes}\PY{p}{:}
                \PY{n}{classes}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{value}\PY{p}{)}
                \PY{n}{counter}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
            \PY{k}{else}\PY{p}{:}
                \PY{n}{counter}\PY{p}{[}\PY{n}{classes}\PY{o}{.}\PY{n}{index}\PY{p}{(}\PY{n}{value}\PY{p}{)}\PY{p}{]} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
        
        \PY{c+c1}{\PYZsh{} Considering only classes with more than 20 samples}
        \PY{n}{classes}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Other}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{counter}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{n}{classesNew} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{p}{)}
        \PY{n}{counterNew} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{p}{)}
        
        \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{el} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{counter}\PY{p}{)}\PY{p}{:}
            \PY{k}{if} \PY{n}{el} \PY{o}{\PYZgt{}} \PY{l+m+mi}{20}\PY{p}{:}
                \PY{n}{classesNew}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{classes}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
                \PY{n}{counterNew}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{el}\PY{p}{)}
            \PY{k}{else}\PY{p}{:}
                \PY{n}{counter}\PY{p}{[}\PY{n+nb}{len}\PY{p}{(}\PY{n}{counter}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{+}\PY{o}{=} \PY{n}{counter}\PY{p}{[}\PY{n}{i}\PY{p}{]}
        
        \PY{n}{classes} \PY{o}{=} \PY{n}{classesNew}
        \PY{n}{counter} \PY{o}{=} \PY{n}{counterNew}
        
        \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{classes}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}:\PYZgt{}3\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{counter}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{classes}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
\end{Verbatim}

\newpage
    \begin{Verbatim}[commandchars=\\\{\}]
	 339   GinMaster
	 613   Opfake
	 925   FakeInstaller
	  27   Boxer
	  29   Jifake
	 667   DroidKungFu
	  41   SMSreg
	  58   Gappusin
	 147   Kmin
	  61   FakeRun
	 625   Plankton
	  28   Hamob
	 132   FakeDoc
	  91   Adrd
	  37   Yzhc
	  69   Glodream
	 330   BaseBridge
	 152   Iconosys
	  70   ExploitLinuxLotoor
	  59   SendPay
	  92   Geinimi
	  81   DroidDream
	  43   Imlog
	  69   MobileTx
	 775   Other

    \end{Verbatim}

    \hypertarget{chosen-ones}{%
\subsubsection{Chosen Ones}\label{chosen-ones}}

In order to reduce the input vector dimension and fine-tune the
training, only a few features are chosen to be extracted. Deeper
consideration will be done later about this specific selection.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{chosenFeatures} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{permission}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{api\PYZus{}call}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{service\PYZus{}receiver}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\end{Verbatim}

    \hypertarget{features-extraction}{%
\subsubsection{Features Extraction}\label{features-extraction}}

The following function has the purpose to, given as input the feature
name and its subsequent string, identify the best function to extract
the feature and return as output a vector of words which will be used to
build the dictionary of words or the vector of features.

The algorithm presented here is using just the most important word of
each line of the document, for example touchscreen and MAIN, and
discarding words less relevant (android, hardware, intent and action) as
the lines shown below.

\begin{verbatim}
feature::android.hardware.touchscreen
intent::android.intent.action.MAIN
\end{verbatim}

The alghoritm perform that way also because the firsts are common words
which do not improve the training results, because they add no more
information to the input vector.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{k}{def} \PY{n+nf}{selfExtraction}\PY{p}{(}\PY{n}{feature}\PY{p}{,} \PY{n}{string}\PY{p}{)}\PY{p}{:}
            \PY{k}{def} \PY{n+nf}{extractUrl}\PY{p}{(}\PY{n}{string}\PY{p}{)}\PY{p}{:}
                \PY{k}{try}\PY{p}{:}
                    \PY{n}{baseUrl} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}0.scheme\PYZcb{}}\PY{l+s+s2}{://}\PY{l+s+si}{\PYZob{}0.netloc\PYZcb{}}\PY{l+s+s2}{/}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{urlsplit}\PY{p}{(}\PY{n}{string}\PY{p}{)}\PY{p}{)}
                    \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n}{baseUrl}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{l+m+mi}{10}\PY{p}{:}
                        \PY{k}{return} \PY{p}{[}\PY{n}{baseUrl}\PY{p}{]}
                \PY{k}{except}\PY{p}{:}
                    \PY{k}{return} \PY{k+kc}{None}
        
            \PY{k}{def} \PY{n+nf}{extractApiCall}\PY{p}{(}\PY{n}{string}\PY{p}{)}\PY{p}{:}
                \PY{k}{try}\PY{p}{:}
                    \PY{n}{string} \PY{o}{=} \PY{n}{string}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{;\PYZhy{}\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                    \PY{n}{apiCall} \PY{o}{=} \PY{n}{string}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                    \PY{k}{return} \PY{n}{apiCall}
                \PY{k}{except}\PY{p}{:}
                    \PY{k}{return} \PY{k+kc}{None}
        
            \PY{k}{def} \PY{n+nf}{extractFeature}\PY{p}{(}\PY{n}{string}\PY{p}{)}\PY{p}{:}
                \PY{k}{try}\PY{p}{:}
                    \PY{n}{feature} \PY{o}{=} \PY{n}{string}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
                    \PY{k}{return} \PY{p}{[}\PY{n}{feature}\PY{p}{]}
                \PY{k}{except}\PY{p}{:}
                    \PY{k}{return} \PY{k+kc}{None}
        
            \PY{k}{def} \PY{n+nf}{extractPermission}\PY{p}{(}\PY{n}{string}\PY{p}{)}\PY{p}{:}
                \PY{k}{try}\PY{p}{:}
                    \PY{n}{permission} \PY{o}{=} \PY{n}{string}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}
                    \PY{k}{return} \PY{p}{[}\PY{n}{permission}\PY{p}{]}
                \PY{k}{except}\PY{p}{:}
                    \PY{k}{return} \PY{k+kc}{None}
        
            \PY{k}{def} \PY{n+nf}{extractCall}\PY{p}{(}\PY{n}{string}\PY{p}{)}\PY{p}{:}
                \PY{k}{try}\PY{p}{:}
                    \PY{n}{call} \PY{o}{=} \PY{n}{string}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}
                    \PY{k}{return} \PY{p}{[}\PY{n}{call}\PY{p}{]}
                \PY{k}{except}\PY{p}{:}
                    \PY{k}{return} \PY{k+kc}{None}
        
            \PY{k}{def} \PY{n+nf}{extractActivity}\PY{p}{(}\PY{n}{string}\PY{p}{)}\PY{p}{:}
                \PY{k}{try}\PY{p}{:}
                    \PY{n}{activity} \PY{o}{=} \PY{n}{string}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}
                    \PY{k}{if} \PY{n}{activity}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}
                        \PY{n}{activity} \PY{o}{=} \PY{n}{activity}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}
                    \PY{k}{return} \PY{p}{[}\PY{n}{activity}\PY{p}{]}
                \PY{k}{except}\PY{p}{:}
                    \PY{k}{return} \PY{k+kc}{None}
        
            \PY{k}{def} \PY{n+nf}{extractIntent}\PY{p}{(}\PY{n}{string}\PY{p}{)}\PY{p}{:}
                \PY{k}{try}\PY{p}{:}
                    \PY{n}{intent} \PY{o}{=} \PY{n}{string}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}
                    \PY{k}{return} \PY{p}{[}\PY{n}{intent}\PY{p}{]}
                \PY{k}{except}\PY{p}{:}
                    \PY{k}{return} \PY{k+kc}{None}
        
            \PY{k}{def} \PY{n+nf}{extractServiceReceiver}\PY{p}{(}\PY{n}{string}\PY{p}{)}\PY{p}{:}
                \PY{k}{try}\PY{p}{:}
                    \PY{n}{serviceReceiver} \PY{o}{=} \PY{n}{string}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}
                    \PY{k}{return} \PY{p}{[}\PY{n}{serviceReceiver}\PY{p}{]}
                \PY{k}{except}\PY{p}{:}
                    \PY{k}{return} \PY{k+kc}{None}
        
            \PY{k}{def} \PY{n+nf}{extractProvider}\PY{p}{(}\PY{n}{string}\PY{p}{)}\PY{p}{:}
                \PY{k}{try}\PY{p}{:}
                    \PY{n}{provider} \PY{o}{=} \PY{n}{string}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}
                    \PY{k}{if} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s2}{\PYZdq{}} \PY{o+ow}{in} \PY{n}{provider}\PY{p}{:}
                        \PY{n}{provider} \PY{o}{=} \PY{n}{provider}\PY{p}{[}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{]}
                    \PY{k}{return} \PY{p}{[}\PY{n}{provider}\PY{p}{]}
                \PY{k}{except}\PY{p}{:}
                    \PY{k}{return} \PY{k+kc}{None}
        
            \PY{n}{switcher} \PY{o}{=} \PY{p}{\PYZob{}}
                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{url}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{extractUrl}\PY{p}{,}
                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{api\PYZus{}call}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{extractApiCall}\PY{p}{,}
                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{extractFeature}\PY{p}{,}
                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{permission}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{extractPermission}\PY{p}{,}
                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{real\PYZus{}permission}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{extractPermission}\PY{p}{,}
                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{call}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{extractCall}\PY{p}{,}
                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{extractActivity}\PY{p}{,}
                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{extractIntent}\PY{p}{,}
                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{service\PYZus{}receiver}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{extractServiceReceiver}\PY{p}{,}
                \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{provider}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{extractProvider}
            \PY{p}{\PYZcb{}}
            \PY{k}{return} \PY{n}{switcher}\PY{p}{[}\PY{n}{feature}\PY{p}{]}\PY{p}{(}\PY{n}{string}\PY{p}{)}
\end{Verbatim}

    \hypertarget{words-indices-vector}{%
\subsubsection{Words Indices Vector}\label{words-indices-vector}}

The network is fed with a set of vectors, which elements are the indices
of each word belonging to the specific file, mapped from a dictionary of
all the words obtained from the feature extraction of the entire dataset
of files.

The dictionary is previously generated through the same function, as
shown below.

For instance, considering the file

\begin{verbatim}
612aa197794bc4c88bd7dbed41a9b13b9969befb645761fa384b1a567a50ceee
\end{verbatim}

Its own Word Vectore will be

\begin{verbatim}
[0, 25, 26, 126, 111, 22, 3, 7, 8, 10, 11, 33, 19]
\end{verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{k}{def} \PY{n+nf}{processFile}\PY{p}{(}\PY{n}{file}\PY{p}{,} \PY{n}{dictionary}\PY{p}{,} \PY{n}{outputCreation} \PY{o}{=} \PY{k+kc}{False}\PY{p}{,} \PY{n}{dictionaryCreation}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} List of words of each file}
            \PY{n}{words} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} Read line by line of the file}
            \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{n}{datasetFolder} \PY{o}{+} \PY{n}{featuresFolder} \PY{o}{+} \PY{n}{file}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
                \PY{n}{content} \PY{o}{=} \PY{n}{f}\PY{o}{.}\PY{n}{readlines}\PY{p}{(}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} Divide each line of document in feature name and its subsequent string}
                \PY{k}{for} \PY{n}{line} \PY{o+ow}{in} \PY{n}{content}\PY{p}{:}
                    \PY{k}{try}\PY{p}{:}
                        \PY{n}{split} \PY{o}{=} \PY{n}{line}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{::}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                        \PY{n}{category} \PY{o}{=} \PY{n}{split}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                        \PY{n}{string} \PY{o}{=} \PY{n}{split}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
                    \PY{k}{except}\PY{p}{:}
                        \PY{k}{break}
                    
                    \PY{n}{wordList} \PY{o}{=} \PY{k+kc}{None}
                    \PY{k}{if} \PY{n}{category} \PY{o+ow}{in} \PY{n}{chosenFeatures}\PY{p}{:}
                        \PY{n}{wordList} \PY{o}{=} \PY{n}{selfExtraction}\PY{p}{(}\PY{n}{category}\PY{p}{,} \PY{n}{string}\PY{p}{)}
        
                    \PY{c+c1}{\PYZsh{} If able to extract feature from line}
                    \PY{k}{if} \PY{n}{wordList} \PY{o}{!=} \PY{k+kc}{None}\PY{p}{:}
                        \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{wordList}\PY{p}{:}
                            \PY{n}{word} \PY{o}{=} \PY{n}{word}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                            \PY{c+c1}{\PYZsh{} If flagged to create the dictionary}
                            \PY{k}{if} \PY{n}{dictionaryCreation}\PY{p}{:}
                                \PY{k}{if} \PY{o+ow}{not} \PY{n}{word} \PY{o+ow}{in} \PY{n}{dictionary}\PY{p}{:}
                                    \PY{n}{index} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{dictionary}\PY{p}{)}
                                    \PY{n}{dictionary}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{=} \PY{n}{index}
                            \PY{k}{else}\PY{p}{:}
                                \PY{n}{index} \PY{o}{=} \PY{n}{dictionary}\PY{p}{[}\PY{n}{word}\PY{p}{]}
                                \PY{k}{if} \PY{n}{index} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{words}\PY{p}{:}
                                    \PY{n}{words}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{index}\PY{p}{)}
                \PY{c+c1}{\PYZsh{}If flagged to create the output vector of categories}
                \PY{k}{if} \PY{n}{outputCreation}\PY{p}{:}
                    \PY{k}{if} \PY{n}{malwareDictionary}\PY{p}{[}\PY{n}{file}\PY{p}{]} \PY{o+ow}{in} \PY{n}{classes}\PY{p}{:}
                        \PY{n}{y}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{classes}\PY{o}{.}\PY{n}{index}\PY{p}{(}\PY{n}{malwareDictionary}\PY{p}{[}\PY{n}{file}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                    \PY{k}{else}\PY{p}{:}
                        \PY{n}{y}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{classes}\PY{o}{.}\PY{n}{index}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Other}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
        
            \PY{k}{return} \PY{n}{words}
\end{Verbatim}

\newpage
    \hypertarget{dictionary-generation-and-loading}{%
\subsubsection{Dictionary Generation and
Loading}\label{dictionary-generation-and-loading}}

The above-mentioned dictionary is, at first, searched into the main
folder and, if not found, generated and stored in a json file for a
better readablity and due to its huge size.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{k}{if} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{isfile}\PY{p}{(}\PY{n}{dictionaryName}\PY{p}{)}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dictionary file found!}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{n}{dictionaryName}\PY{p}{)} \PY{k}{as} \PY{n}{d}\PY{p}{:}
                 \PY{n}{dictionary} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{d}\PY{p}{)}
             \PY{n}{d}\PY{o}{.}\PY{n}{close}\PY{p}{(}\PY{p}{)}
         
         \PY{k}{else}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dictionary file not found!}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Define the dictionary}
             \PY{n}{dictionary} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
             
             \PY{c+c1}{\PYZsh{} Colect words for malware}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Creating dictionary}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{dataset}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                 \PY{n}{processFile}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{dictionary}\PY{p}{,} \PY{n}{dictionaryCreation}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
             
             \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{n}{dictionaryName}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w+}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{d}\PY{p}{:}
                 \PY{n}{d}\PY{o}{.}\PY{n}{write}\PY{p}{(}\PY{n}{json}\PY{o}{.}\PY{n}{dumps}\PY{p}{(}\PY{n}{dictionary}\PY{p}{,} \PY{n}{sort\PYZus{}keys}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{indent}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
             \PY{n}{d}\PY{o}{.}\PY{n}{close}\PY{p}{(}\PY{p}{)}
                 
         
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Dictionary saved to file!}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Print number of words in the dictionary}
         \PY{n}{dictionarySize} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{dictionary}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dictionary size: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{dictionarySize}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Dictionary file not found!
Creating dictionary

Dictionary saved to file!
Dictionary size:  1733

    \end{Verbatim}
    
\newpage
    \hypertarget{building-input-and-output}{%
\subsubsection{Building Input and
Output}\label{building-input-and-output}}

Through the above-mentioned function used to extract features from the
malware files, the actual input (X) and output (y) that will feed the
network are finally built.

In order to have a homogeneus size of input, the one-hot encoded version
of the word vectors are built, starting from the length of the
dictionary to generate a list containing only zeros, and replacing that
values with ones at the indices specified by the output of the feature
extraction function. One vector for file is then appended to the input
list.

Moreover, for each file, the category index of that malware is appended
to the output list, setting to True the boolean variable
``outputCreation''.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{}List of features}
         \PY{n}{X} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{}List of categories}
         \PY{n}{y} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Construct the vector of features and output vector at the same time}
         \PY{k}{def} \PY{n+nf}{featuresExtraction}\PY{p}{(}\PY{n}{file}\PY{p}{,} \PY{n}{dictionary}\PY{p}{)}\PY{p}{:}
             \PY{n}{indices} \PY{o}{=} \PY{n}{processFile}\PY{p}{(}\PY{n}{file}\PY{p}{,} \PY{n}{dictionary}\PY{p}{,} \PY{n}{outputCreation}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
             \PY{n}{feat} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n+nb}{len}\PY{p}{(}\PY{n}{dictionary}\PY{p}{)}
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n}{indices}\PY{p}{:}
                 \PY{n}{feat}\PY{p}{[}\PY{n}{i}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
         
             \PY{k}{return} \PY{n}{feat}
         \PY{c+c1}{\PYZsh{} Extract features and append to the list of features}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Extracting Features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{malware}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{feat} \PY{o}{=} \PY{n}{featuresExtraction}\PY{p}{(}\PY{n}{malware}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{dictionary}\PY{p}{)}
             \PY{n}{X}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{feat}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Extraction Complete}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Extracting Features
Extraction Complete

    \end{Verbatim}

    \hypertarget{train-test-split}{%
\subsubsection{Train Test Split}\label{train-test-split}}

In order to have a good evaluation of the used algorithm, it is
important to separate the dataset between training and test set. The
training set will be used to train the classifier and the test set will
only be used to calculate the metrics.

It is important for the classifier do not see the test set before,
because it could overfit the data and not be able to generalize for new
examples.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{} Split randomly the dataset into train and evaluation }
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{)}
\end{Verbatim}

\newpage
    \hypertarget{classifiers}{%
\section{Classifiers}\label{classifiers}}

For this project, three classifiers were chosen to be trained with the
same dataset. The first classifier is the Naive Bayes, the second one is
Support Vector Machines and the third one is Random Forest.

Follows a brief description of the above-mentioned classifiers,
highlighting the pros and cons for each method.

\hypertarget{naive-bayes}{%
\subsubsection{Naive Bayes}\label{naive-bayes}}

Naive Bayes is a probabilistic classifier inspired by the Bayes theorem
under a simple assumption which is the attributes are conditionally
independent.

The classification is conducted by deriving the maximum posterior which
is the maximal P(Ci\textbar{}X) with the above assumption applying to
Bayes theorem. This assumption greatly reduces the computational cost by
only counting the class distribution. Even though the assumption is not
valid in most cases since the attributes are dependent, surprisingly
Naive Bayes has able to perform impressively.

Naive Bayes is a very simple algorithm to implement and good results
have obtained in most cases. It can be easily scalable to larger
datasets since it takes linear time, rather than by expensive iterative
approximation as used for many other types of classifiers.

Naive Bayes can suffer from a problem called the zero probability
problem. When the conditional probability is zero for a particular
attribute, it fails to give a valid prediction. This needs to be fixed
explicitly using a Laplacian estimator.

\hypertarget{support-vector-machine}{%
\subsubsection{Support Vector Machine}\label{support-vector-machine}}

SVM or Support Vector Machine is a linear model for classification and
regression problems. It can solve linear and non-linear problems and
work well for many practical problems. The idea of SVM is simple: The
algorithm creates a line or a hyperplane which separates the data into
classes.

SVM is mostly useful in non-linear separation problems, because it has a
technique called the kernel trick, these are functions which takes low
dimensional input space and transform it to a higher dimensional space,
which means that it converts not separable problem to separable problem.

SVM performs similarly to logistic regression (really well) when with
clear margins of linear separation.

On the contrary, it does not perform well when we have large data set,
because the required training time is higher, and when the dataset has
more noise, which means that target classes are overlapping.

Tuning Parameters?


\newpage
\hypertarget{random-forest}{%
\subsubsection{Random Forest}\label{random-forest}}

Random Forest is an example of an ensemble method, in which we combine
multiple machine learning algorithms to obtain better predictive
performance. We'll run multiple models on the data and use the aggregate
predictions, which will be better than a single model alone.

The idea behind a Random Forest is actually pretty simple: We repeatedly
select data from the data set (with replacement) and build a Decision
Tree with each new sample. It is important to note that since we are
sampling with replacement, many data points will be repeated and many
won't be included as well. This is important to keep in mind when we
talk about measuring error of a Random Forest. Another important feature
of the Random Forest is that each node of the Decision Tree is limited
to only considering splits on random subsets of the features.

One big advantage of Random Forest is, that it can be used for both
classification and regression problems, which form the majority of
current machine learning systems.

On the contrary, Random Forest produces results not easy to visually
interpret and it can overfit with some datasets with noisy
classification/regression tasks.

    \hypertarget{training-and-results}{%
\section{Training and Results}\label{training-and-results}}

\hypertarget{training-function}{%
\subsubsection{Training Function}\label{training-function}}

After having all the functions for the analysis explained and
implemented, it is possible to train it with the training data and
validate with the test data.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{n}{y\PYZus{}predict} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{p}{)}
         \PY{n}{classifiers} \PY{o}{=} \PY{p}{[}
                 \PY{n}{MultinomialNB}\PY{p}{(}\PY{p}{)}\PY{p}{,}
                 \PY{n}{SVC}\PY{p}{(}\PY{n}{kernel}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{linear}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{probability}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
                 \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
         \PY{p}{]}
         \PY{n}{log\PYZus{}cols}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Log Loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Time}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
         \PY{n}{log} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{n}{log\PYZus{}cols}\PY{p}{)}
         
         \PY{k}{for} \PY{n}{clf} \PY{o+ow}{in} \PY{n}{classifiers}\PY{p}{:}
             \PY{n}{t}\PY{o}{=}\PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}
             \PY{n}{clf}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
             \PY{n}{t2} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}
             \PY{n}{name} \PY{o}{=} \PY{n}{clf}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}class\PYZus{}\PYZus{}}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}}
             
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{=}\PY{l+s+s2}{\PYZdq{}}\PY{o}{*}\PY{l+m+mi}{30}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{name}\PY{p}{)}
             
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{****Results****}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{train\PYZus{}predictions} \PY{o}{=} \PY{n}{clf}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
             \PY{n}{y\PYZus{}predict}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{train\PYZus{}predictions}\PY{p}{)}
             \PY{n}{acc} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{train\PYZus{}predictions}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+si}{\PYZob{}:.4\PYZpc{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{acc}\PY{p}{)}\PY{p}{)}
             
             \PY{n}{train\PYZus{}predictions} \PY{o}{=} \PY{n}{clf}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
             \PY{n}{ll} \PY{o}{=} \PY{n}{log\PYZus{}loss}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{train\PYZus{}predictions}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Log Loss: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{ll}\PY{p}{)}\PY{p}{)}
         
             \PY{n}{timeSpent} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{t2}\PY{o}{\PYZhy{}}\PY{n}{t}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Time to Train: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ s}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{timeSpent}\PY{p}{)}\PY{p}{)}
             
             \PY{n}{log\PYZus{}entry} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{name}\PY{p}{,} \PY{n}{acc}\PY{o}{*}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{ll}\PY{p}{,} \PY{n}{timeSpent}\PY{p}{]}\PY{p}{]}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{n}{log\PYZus{}cols}\PY{p}{)}
             \PY{n}{log} \PY{o}{=} \PY{n}{log}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{log\PYZus{}entry}\PY{p}{)}
             
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{=}\PY{l+s+s2}{\PYZdq{}}\PY{o}{*}\PY{l+m+mi}{30}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
==============================
MultinomialNB
****Results****
Accuracy: 85.8813\%
Log Loss: 1.1335253415771336
Time to Train: 0.6 s
==============================
SVC
****Results****
Accuracy: 95.7734\%
Log Loss: 0.20580616263825374
Time to Train: 48.0 s
==============================
RandomForestClassifier
****Results****
Accuracy: 95.6835\%
Log Loss: 0.27335448783949584
Time to Train: 2.97 s
==============================

    \end{Verbatim}

    \hypertarget{graphical-results}{%
\subsubsection{Graphical Results}\label{graphical-results}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}color\PYZus{}codes}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{muted}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Classifier}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{log}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{b}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy }\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Classifier Accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{figure}
\centering
\includegraphics{images/accuracy.png}
\end{figure}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}color\PYZus{}codes}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{muted}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Log Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Classifier}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{log}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Log Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Classifier Log Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{figure}
\centering
\includegraphics{images/logloss.png}
\end{figure}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}color\PYZus{}codes}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{muted}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Classifier}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{log}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Classifier Time to Train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{figure}
\centering
\includegraphics{images/timetotrain.png}
\end{figure}

    \hypertarget{final-considerations}{%
\section{Final Considerations}\label{final-considerations}}

\hypertarget{choosen-features-and-classifiers}{%
\subsubsection{Choosen Features and
Classifiers}\label{choosen-features-and-classifiers}}

A wide range of attempts has been made in order to find the categories
that performs better with this classification problem. Almost all the
possibile combinations between the features have been tried,
highlighting that, category such as ``feature'' or ``provider'', which
generates alone a dictionary containing less than 50 words, do not
increase the accuracy when combined with others category, therefore
they'have been deleted from the list.

On the other side, there are categories such as ``permission'' or
``api\_call'' that perform amazing results all alone (an average of 90\%
of accuracy with the three classifiers). It has been easy to maximize
the perfomance starting from those categories.

In all of the attempts, Random Forest and SVM performed a lot better
than Naive Bayes, so the final goal of the task had been maximizing the
perfomance of that specific classifiers. That combination has been found
in the categories ``permission'', ``service\_receiver'' and
``activity''.

\newpage
\hypertarget{from-the-graph}{%
\subsubsection{From the Graph}\label{from-the-graph}}

The graphs showed above highlight streghts and weaknesses of each
classifier, which is an extension of what it has been already told.

Besides the fact that Naive Bayes performs worse than the other two in
most of the cases, also the time spent to train the classifier needs to
be considered. It's clear that the Support Vector Machine is the slowest
one and that's because its fit time complexity is more than quadratic
with the number of samples, which makes it hard to scale to huge dataset
(in this case, samples number equal to the number of malware files).

From the results of this project it's cristal clear that, among the
studied three, the classifier that best fit this classification problem
is the Random Forest.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
