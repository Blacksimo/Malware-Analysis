import os, sys, csv, time, json
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt 
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB, GaussianNB
from sklearn.metrics import classification_report
from sklearn.svm import LinearSVC, SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, log_loss
from urllib.parse import urlsplit

datasetFolder = 'drebin/'
featuresFolder = 'feature_vectors/'
csvName = 'sha256_family.csv'
dictionaryName = 'dictionary.json'

# List of all the files in debrin dataset
dataset = os.listdir(datasetFolder + featuresFolder)

# Define list for malware and non-malware files
malware = list()

# Create malware dictionary from the csv file, with the file name and the type of each one
with open(datasetFolder + csvName) as csvFile:
    reader = csv.reader(csvFile)
    next(reader)
    malwareDictionary = {row[0]: row[1] for row in reader}

# Separate the file names
for i in dataset:
    if i in malwareDictionary:
        malware.append(i)

print('Number of malwares in the dataset:\t', len(malware))

# Collect all the features from the files of the dataset
categoryList = list()
for file in malware:
    with open(datasetFolder + featuresFolder + file) as f:
        content = f.readlines()
        for line in content:
            try:
                category, string = line.split('::')
                if category not in categoryList:
                    categoryList.append(category)
            except:
                print("Empty file: ", file)

print('The features can be divided in',
      len(categoryList), 'different sets:')
print('\t', '\n\t '.join(categoryList))

# Collect all the classes from the files of the dataset
classes = []
counter = []
for key, value in sorted(malwareDictionary.items()):
    if not value in classes:
        classes.append(value)
        counter.append(1)
    else:
        counter[classes.index(value)] += 1

# Considering only classes with more than 20 samples
classes.append("Other")
counter.append(0)
classesNew = list()
counterNew = list()

for i, el in enumerate(counter):
    if el > 20:
        classesNew.append(classes[i])
        counterNew.append(el)
    else:
        counter[len(counter)-1] += counter[i]

classes = classesNew
counter = counterNew

for i in range(len(classes)):
    print('\t', '{:>3}'.format(counter[i]), " ", classes[i])


chosenFeatures = ["permission", "api_call", "service_receiver"]


def selfExtraction(feature, string):
    def extractUrl(string):
        try:
            baseUrl = "{0.scheme}://{0.netloc}/".format(urlsplit(string))
            if len(baseUrl) > 10:
                return [baseUrl]
        except:
            return None

    def extractApiCall(string):
        try:
            string = string.replace(';->', '/')
            apiCall = string.split('/')
            return apiCall
        except:
            return None

    def extractFeature(string):
        try:
            feature = string.split('.')[-1]
            return [feature]
        except:
            return None

    def extractPermission(string):
        try:
            permission = string.split('.')[-1].lower()
            return [permission]
        except:
            return None

    def extractCall(string):
        try:
            call = string.lower()
            return [call]
        except:
            return None

    def extractActivity(string):
        try:
            activity = string.split('.')[-1].lower()
            if activity[0] == ":":
                activity = activity[1:]
            return [activity]
        except:
            return None

    def extractIntent(string):
        try:
            intent = string.split('.')[-1].lower()
            return [intent]
        except:
            return None

    def extractServiceReceiver(string):
        try:
            serviceReceiver = string.split('.')[-1].lower()
            return [serviceReceiver]
        except:
            return None

    def extractProvider(string):
        try:
            provider = string.split('.')[-1].lower()
            if "\\" in provider:
                provider = provider[:-2]
            return [provider]
        except:
            return None

    switcher = {
        'url': extractUrl,
        'api_call': extractApiCall,
        'feature': extractFeature,
        'permission': extractPermission,
        'real_permission': extractPermission,
        'call': extractCall,
        'activity': extractActivity,
        'intent': extractIntent,
        'service_receiver': extractServiceReceiver,
        'provider': extractProvider
    }
    return switcher[feature](string)



def processFile(file, dictionary, outputCreation = False, dictionaryCreation=False):
    # List of words of each file
    words = list()
    # Read line by line of the file
    with open(datasetFolder + featuresFolder + file) as f:
        content = f.readlines()

        # Divide each line of document in feature name and its subsequent string
        for line in content:
            try:
                split = line.split('::')
                category = split[0]
                string = split[1]
            except:
                break
            
            wordList = None
            if category in chosenFeatures:
                wordList = selfExtraction(category, string)

            # If able to extract feature from line
            if wordList != None:
                for word in wordList:
                    word = word.replace('\n', '')
                    # If flagged to create the dictionary
                    if dictionaryCreation:
                        if not word in dictionary:
                            index = len(dictionary)
                            dictionary[word] = index
                    else:
                        index = dictionary[word]
                        if index not in words:
                            words.append(index)
        #If flagged to create the output vector of categories
        if outputCreation:
            if malwareDictionary[file] in classes:
                y.append(classes.index(malwareDictionary[file]))
            else:
                y.append(classes.index("Other"))

    return words

# Check if dictionary exists
if os.path.isfile(dictionaryName):
    print('Dictionary file found!')
    with open(dictionaryName) as d:
        dictionary = json.load(d)
    d.close()

else:
    print('Dictionary file not found!')
    
    # Define the dictionary
    dictionary = {}
    
    # Colect words for malware
    print('Creating dictionary')
    for i in range(len(dataset)):
        processFile(dataset[i], dictionary, dictionaryCreation=True)
    
    with open(dictionaryName, 'w+') as d:
        d.write(json.dumps(dictionary, sort_keys=True, indent=4))
    d.close()
        

    print('\nDictionary saved to file!')

# Print number of words in the dictionary
dictionarySize = len(dictionary)
print('Dictionary size: ', dictionarySize)

#List of features
X = list()
#List of categories
y = list()
# Construct the vector of features and output vector at the same time
def featuresExtraction(file, dictionary):
    indices = processFile(file, dictionary, outputCreation=True)
    feat = [0] * len(dictionary)
    for i in indices:
        feat[i-1] = 1

    return feat
# Extract features and append to the list of features
print('Extracting Features')
for i in range(len(malware)):
    feat = featuresExtraction(malware[i], dictionary)
    X.append(feat)
print('Extraction Complete')


# Splitting randomly the dataset into train and evaluation 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

y_predict = list()
classifiers = [
        MultinomialNB(),
        SVC(kernel="linear", probability=True),
        RandomForestClassifier(n_estimators=100, max_depth=100)
]
log_cols=["Classifier", "Accuracy", "Log Loss", "Time"]
log = pd.DataFrame(columns=log_cols)

for clf in classifiers:
    t=time.time()
    clf.fit(X_train, y_train)
    t2 = time.time()
    name = clf.__class__.__name__
    
    print("="*30)
    print(name)
    
    print('****Results****')
    train_predictions = clf.predict(X_test)
    y_predict.append(train_predictions)
    acc = accuracy_score(y_test, train_predictions)
    print("Accuracy: {:.4%}".format(acc))
    
    train_predictions = clf.predict_proba(X_test)
    ll = log_loss(y_test, train_predictions)
    print("Log Loss: {}".format(ll))

    timeSpent = round(t2-t, 2)
    print("Time to Train: {} s".format(timeSpent))
    
    log_entry = pd.DataFrame([[name, acc*100, ll, timeSpent]], columns=log_cols)
    log = log.append(log_entry)
    
print("="*30)

sns.set_color_codes("muted")
sns.barplot(x='Accuracy', y='Classifier', data=log, color="b")

plt.xlabel('Accuracy %')
plt.title('Classifier Accuracy')
plt.show()

sns.set_color_codes("muted")
sns.barplot(x='Log Loss', y='Classifier', data=log, color="g")

plt.xlabel('Log Loss')
plt.title('Classifier Log Loss')
plt.show()

sns.set_color_codes("muted")
sns.barplot(x='Time', y='Classifier', data=log, color="r")

plt.xlabel('Time')
plt.title('Classifier Time to Train')
plt.show()
""" 
def trainClassifer(X_train, X_test, y_train, method='Support Vector Machine'):
    
    switcher = {
        'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=100, random_state=0),
        #'Support Vector Machine': svm.SVC(gamma='scale', decision_function_shape='ovo'),
        'Support Vector Machine': LinearSVC(),
        'Naive Bayes': GaussianNB()
    }

    # Define the classifier
    classifier = switcher[method]
    
    # Check the training time for the SVC
    t=time.time()
    classifier.fit(X_train, y_train)
    t2 = time.time()
    print(round(t2-t, 2), 'Seconds to train Classifier...')
    
    # Check the score of the SVC
    y_predict=classifier.predict(X_test)

    return y_predict




usedClasses = []
for el in y_test:
    if classes[el] not in usedClasses:
        usedClasses.append(classes[el])

y_predict = trainClassifer(X_train, X_test, y_train, method="Random Forest")
print("==" * 10)
print("Random Forest")
print("==" * 10)
print(classification_report(y_test, y_predict, target_names=usedClasses))

y_predict = trainClassifer(X_train, X_test, y_train)
print("==" * 10)
print("SVM")
print("==" * 10)
print(classification_report(y_test, y_predict, target_names=usedClasses))

y_predict = trainClassifer(X_train, X_test, y_train, method="Naive Bayes")
print("==" * 10)
print("Naive Bayes")
print("==" * 10)
print(classification_report(y_test, y_predict, target_names=usedClasses)) """